{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.optimizers import adam_v2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras_metrics\n",
    "from keras import metrics\n",
    "from keras import backend as K\n",
    "from keras.regularizers import l2\n",
    "import keras\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train_preprocessed-nonPCA.csv',index_col=[0])\n",
    "df_test = pd.read_csv('test_preprocessed-nonPCA.csv',index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40736, 118)\n",
      "(40736,)\n",
      "(10184, 118)\n",
      "(10184,)\n"
     ]
    }
   ],
   "source": [
    "X_train=df_train.iloc[:,:-1].values\n",
    "y_train=df_train.iloc[:,-1].values\n",
    "X_test=df_test.iloc[:,:-1].values\n",
    "y_test=df_test.iloc[:,-1].values\n",
    "\n",
    "# print the shape of the split dataset\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0],118,1)\n",
    "X_test = X_test.reshape(X_test.shape[0],118,1)\n",
    "\n",
    "y_train = to_categorical(y_train, 4)\n",
    "y_test = to_categorical(y_test, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4074/4074 [==============================] - 35s 8ms/step - loss: 1.2507 - accuracy: 0.4558 - val_loss: 1.1936 - val_accuracy: 0.4733\n",
      "Epoch 2/50\n",
      "4074/4074 [==============================] - 32s 8ms/step - loss: 1.1925 - accuracy: 0.4812 - val_loss: 1.1895 - val_accuracy: 0.4735\n",
      "Epoch 3/50\n",
      "4074/4074 [==============================] - 25s 6ms/step - loss: 1.1799 - accuracy: 0.4847 - val_loss: 1.1743 - val_accuracy: 0.4811\n",
      "Epoch 4/50\n",
      "4074/4074 [==============================] - 15s 4ms/step - loss: 1.1708 - accuracy: 0.4913 - val_loss: 1.1706 - val_accuracy: 0.4827\n",
      "Epoch 5/50\n",
      "4074/4074 [==============================] - 16s 4ms/step - loss: 1.1628 - accuracy: 0.4917 - val_loss: 1.1766 - val_accuracy: 0.4802\n",
      "Epoch 6/50\n",
      "4074/4074 [==============================] - 15s 4ms/step - loss: 1.1586 - accuracy: 0.4966 - val_loss: 1.1772 - val_accuracy: 0.4799\n",
      "Epoch 7/50\n",
      "4074/4074 [==============================] - 16s 4ms/step - loss: 1.1563 - accuracy: 0.4958 - val_loss: 1.1774 - val_accuracy: 0.4841\n",
      "Epoch 8/50\n",
      "4074/4074 [==============================] - 20s 5ms/step - loss: 1.1518 - accuracy: 0.4998 - val_loss: 1.1720 - val_accuracy: 0.4850\n",
      "Epoch 9/50\n",
      "4074/4074 [==============================] - 23s 6ms/step - loss: 1.1479 - accuracy: 0.5022 - val_loss: 1.1733 - val_accuracy: 0.4876\n",
      "Epoch 10/50\n",
      "4074/4074 [==============================] - 25s 6ms/step - loss: 1.1437 - accuracy: 0.5063 - val_loss: 1.1824 - val_accuracy: 0.4784\n",
      "Epoch 11/50\n",
      "4074/4074 [==============================] - 24s 6ms/step - loss: 1.1401 - accuracy: 0.5067 - val_loss: 1.1702 - val_accuracy: 0.4885\n",
      "Epoch 12/50\n",
      "4074/4074 [==============================] - 24s 6ms/step - loss: 1.1364 - accuracy: 0.5077 - val_loss: 1.1718 - val_accuracy: 0.4879\n",
      "Epoch 13/50\n",
      "4074/4074 [==============================] - 24s 6ms/step - loss: 1.1344 - accuracy: 0.5096 - val_loss: 1.1771 - val_accuracy: 0.4821\n",
      "Epoch 14/50\n",
      "4074/4074 [==============================] - 25s 6ms/step - loss: 1.1285 - accuracy: 0.5118 - val_loss: 1.1903 - val_accuracy: 0.4762\n",
      "Epoch 15/50\n",
      "4074/4074 [==============================] - 23s 6ms/step - loss: 1.1254 - accuracy: 0.5167 - val_loss: 1.1808 - val_accuracy: 0.4799\n",
      "Epoch 16/50\n",
      "4074/4074 [==============================] - 24s 6ms/step - loss: 1.1215 - accuracy: 0.5162 - val_loss: 1.1827 - val_accuracy: 0.4786\n",
      "Epoch 17/50\n",
      "4074/4074 [==============================] - 24s 6ms/step - loss: 1.1208 - accuracy: 0.5184 - val_loss: 1.1824 - val_accuracy: 0.4808\n",
      "Epoch 18/50\n",
      "4074/4074 [==============================] - 23s 6ms/step - loss: 1.1152 - accuracy: 0.5198 - val_loss: 1.1880 - val_accuracy: 0.4864\n",
      "Epoch 19/50\n",
      "4074/4074 [==============================] - 23s 6ms/step - loss: 1.1087 - accuracy: 0.5222 - val_loss: 1.1944 - val_accuracy: 0.4858\n",
      "Epoch 20/50\n",
      "4074/4074 [==============================] - 23s 6ms/step - loss: 1.1081 - accuracy: 0.5249 - val_loss: 1.1946 - val_accuracy: 0.4830\n",
      "Epoch 21/50\n",
      "4074/4074 [==============================] - 24s 6ms/step - loss: 1.1052 - accuracy: 0.5274 - val_loss: 1.1930 - val_accuracy: 0.4797\n",
      "Epoch 22/50\n",
      "4074/4074 [==============================] - 24s 6ms/step - loss: 1.1020 - accuracy: 0.5283 - val_loss: 1.1905 - val_accuracy: 0.4823\n",
      "Epoch 23/50\n",
      "4074/4074 [==============================] - 24s 6ms/step - loss: 1.0973 - accuracy: 0.5311 - val_loss: 1.1929 - val_accuracy: 0.4819\n",
      "Epoch 24/50\n",
      "4074/4074 [==============================] - 27s 7ms/step - loss: 1.0943 - accuracy: 0.5320 - val_loss: 1.2039 - val_accuracy: 0.4804\n",
      "Epoch 25/50\n",
      "4074/4074 [==============================] - 24s 6ms/step - loss: 1.0918 - accuracy: 0.5329 - val_loss: 1.2099 - val_accuracy: 0.4789\n",
      "Epoch 26/50\n",
      "4074/4074 [==============================] - 27s 7ms/step - loss: 1.0874 - accuracy: 0.5343 - val_loss: 1.2032 - val_accuracy: 0.4801\n",
      "Epoch 27/50\n",
      "4074/4074 [==============================] - 27s 7ms/step - loss: 1.0835 - accuracy: 0.5373 - val_loss: 1.2064 - val_accuracy: 0.4854\n",
      "Epoch 28/50\n",
      "4074/4074 [==============================] - 24s 6ms/step - loss: 1.0798 - accuracy: 0.5399 - val_loss: 1.2167 - val_accuracy: 0.4716\n",
      "Epoch 29/50\n",
      "4074/4074 [==============================] - 24s 6ms/step - loss: 1.0764 - accuracy: 0.5403 - val_loss: 1.2395 - val_accuracy: 0.4786\n",
      "Epoch 30/50\n",
      "4074/4074 [==============================] - 25s 6ms/step - loss: 1.0755 - accuracy: 0.5438 - val_loss: 1.2193 - val_accuracy: 0.4737\n",
      "Epoch 31/50\n",
      "4074/4074 [==============================] - 26s 6ms/step - loss: 1.0702 - accuracy: 0.5444 - val_loss: 1.2221 - val_accuracy: 0.4749\n",
      "Epoch 31: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu',\n",
    "                     input_shape=(X_train.shape[1], 1),\n",
    "                     kernel_regularizer=l2(0.01))) # 添加L2正则化\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu',\n",
    "                     kernel_regularizer=l2(0.01))) # 添加L2正则化\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=2)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics='accuracy')\n",
    "history = model.fit(X_train, y_train, epochs=50, verbose=1,batch_size=10, validation_data=(X_test, y_test),callbacks=[early_stopping],shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2ed4c9511c8>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "# plot loss during training\n",
    "pyplot.subplot(211)\n",
    "pyplot.title('Loss')\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319/319 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10184, 4)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果y_test是one-hot编码的，将其转换为整数标签\n",
    "if len(y_test.shape) == 2 and y_test.shape[1] > 1:\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "# 如果y_pred是概率，取概率最大的索引作为预测类别\n",
    "if len(y_pred.shape) == 2 and y_pred.shape[1] > 1:\n",
    "    y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "def evaluate(y_pred, y_test):\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.72      0.59      3400\n",
      "           1       0.29      0.07      0.11      2028\n",
      "           2       0.44      0.53      0.48      3162\n",
      "           3       0.54      0.37      0.44      1594\n",
      "\n",
      "    accuracy                           0.47     10184\n",
      "   macro avg       0.44      0.42      0.40     10184\n",
      "weighted avg       0.45      0.47      0.44     10184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# non-co\n",
    "evaluate(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319/319 [==============================] - 1s 3ms/step\n",
      "Multi-class AUROC (One-vs-Rest): 0.7046218196144606\n"
     ]
    }
   ],
   "source": [
    "# non-co\n",
    "from sklearn.preprocessing import label_binarize\n",
    "y_bin = label_binarize(y_test, classes=[0, 1, 2, 3])\n",
    "y_pred_proba = model.predict(X_test)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "auroc = roc_auc_score(y_test, y_pred_proba, multi_class=\"ovr\", average=\"macro\")\n",
    "print(f\"Multi-class AUROC (One-vs-Rest): {auroc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.71      0.60      3400\n",
      "           1       0.27      0.01      0.02      2028\n",
      "           2       0.44      0.59      0.50      3162\n",
      "           3       0.53      0.40      0.46      1594\n",
      "\n",
      "    accuracy                           0.49     10184\n",
      "   macro avg       0.44      0.43      0.40     10184\n",
      "weighted avg       0.45      0.49      0.43     10184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 80\n",
    "evaluate(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319/319 [==============================] - 1s 4ms/step\n",
      "Multi-class AUROC (One-vs-Rest): 0.7128555903854668\n"
     ]
    }
   ],
   "source": [
    "# 80\n",
    "from sklearn.preprocessing import label_binarize\n",
    "y_bin = label_binarize(y_test, classes=[0, 1, 2, 3])\n",
    "y_pred_proba = model.predict(X_test)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "auroc = roc_auc_score(y_test, y_pred_proba, multi_class=\"ovr\", average=\"macro\")\n",
    "print(f\"Multi-class AUROC (One-vs-Rest): {auroc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.62      0.58      3400\n",
      "           1       0.31      0.06      0.10      2028\n",
      "           2       0.42      0.59      0.49      3162\n",
      "           3       0.49      0.42      0.45      1594\n",
      "\n",
      "    accuracy                           0.47     10184\n",
      "   macro avg       0.44      0.43      0.41     10184\n",
      "weighted avg       0.45      0.47      0.44     10184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 50\n",
    "evaluate(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319/319 [==============================] - 1s 2ms/step\n",
      "Multi-class AUROC (One-vs-Rest): 0.7041443437046682\n"
     ]
    }
   ],
   "source": [
    "# 50\n",
    "from sklearn.preprocessing import label_binarize\n",
    "y_bin = label_binarize(y_test, classes=[0, 1, 2, 3])\n",
    "y_pred_proba = model.predict(X_test)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "auroc = roc_auc_score(y_test, y_pred_proba, multi_class=\"ovr\", average=\"macro\")\n",
    "print(f\"Multi-class AUROC (One-vs-Rest): {auroc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.71      0.60      3400\n",
      "           1       0.30      0.04      0.07      2028\n",
      "           2       0.43      0.56      0.49      3162\n",
      "           3       0.51      0.39      0.44      1594\n",
      "\n",
      "    accuracy                           0.48     10184\n",
      "   macro avg       0.44      0.42      0.40     10184\n",
      "weighted avg       0.45      0.48      0.44     10184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 100\n",
    "evaluate(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319/319 [==============================] - 1s 3ms/step\n",
      "Multi-class AUROC (One-vs-Rest): 0.7058737199530687\n"
     ]
    }
   ],
   "source": [
    "# 100\n",
    "from sklearn.preprocessing import label_binarize\n",
    "y_bin = label_binarize(y_test, classes=[0, 1, 2, 3])\n",
    "y_pred_proba = model.predict(X_test)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "auroc = roc_auc_score(y_test, y_pred_proba, multi_class=\"ovr\", average=\"macro\")\n",
    "print(f\"Multi-class AUROC (One-vs-Rest): {auroc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for fold 1 ...\n",
      "Epoch 1/50\n",
      "3259/3259 [==============================] - 23s 6ms/step - loss: 1.3780 - accuracy: 0.4142 - val_loss: 1.2844 - val_accuracy: 0.4340\n",
      "Epoch 2/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2900 - accuracy: 0.4357 - val_loss: 1.2772 - val_accuracy: 0.4368\n",
      "Epoch 3/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2823 - accuracy: 0.4379 - val_loss: 1.2687 - val_accuracy: 0.4417\n",
      "Epoch 4/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2790 - accuracy: 0.4423 - val_loss: 1.2758 - val_accuracy: 0.4381\n",
      "Epoch 5/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2775 - accuracy: 0.4406 - val_loss: 1.2627 - val_accuracy: 0.4455\n",
      "Epoch 6/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2756 - accuracy: 0.4428 - val_loss: 1.2652 - val_accuracy: 0.4455\n",
      "Epoch 7/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2742 - accuracy: 0.4420 - val_loss: 1.2746 - val_accuracy: 0.4413\n",
      "Epoch 8/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2733 - accuracy: 0.4485 - val_loss: 1.2635 - val_accuracy: 0.4440\n",
      "Epoch 9/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2729 - accuracy: 0.4449 - val_loss: 1.2607 - val_accuracy: 0.4487\n",
      "Epoch 10/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2695 - accuracy: 0.4494 - val_loss: 1.2545 - val_accuracy: 0.4567\n",
      "Epoch 11/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2686 - accuracy: 0.4514 - val_loss: 1.2669 - val_accuracy: 0.4449\n",
      "Epoch 12/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2675 - accuracy: 0.4527 - val_loss: 1.2650 - val_accuracy: 0.4476\n",
      "Epoch 13/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2665 - accuracy: 0.4534 - val_loss: 1.2574 - val_accuracy: 0.4574\n",
      "Epoch 14/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2672 - accuracy: 0.4524 - val_loss: 1.2499 - val_accuracy: 0.4535\n",
      "Epoch 15/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2659 - accuracy: 0.4500 - val_loss: 1.2720 - val_accuracy: 0.4516\n",
      "Epoch 16/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2642 - accuracy: 0.4531 - val_loss: 1.2842 - val_accuracy: 0.4461\n",
      "Epoch 17/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2658 - accuracy: 0.4555 - val_loss: 1.2548 - val_accuracy: 0.4539\n",
      "Epoch 18/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2633 - accuracy: 0.4518 - val_loss: 1.2505 - val_accuracy: 0.4632\n",
      "Epoch 19/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2647 - accuracy: 0.4555 - val_loss: 1.2492 - val_accuracy: 0.4604\n",
      "Epoch 20/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2637 - accuracy: 0.4528 - val_loss: 1.2489 - val_accuracy: 0.4583\n",
      "Epoch 21/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2629 - accuracy: 0.4534 - val_loss: 1.2467 - val_accuracy: 0.4631\n",
      "Epoch 22/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2638 - accuracy: 0.4521 - val_loss: 1.2506 - val_accuracy: 0.4473\n",
      "Epoch 23/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2610 - accuracy: 0.4570 - val_loss: 1.2503 - val_accuracy: 0.4520\n",
      "Epoch 24/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2619 - accuracy: 0.4557 - val_loss: 1.2436 - val_accuracy: 0.4661\n",
      "Epoch 25/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2616 - accuracy: 0.4522 - val_loss: 1.2537 - val_accuracy: 0.4583\n",
      "Epoch 26/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2598 - accuracy: 0.4550 - val_loss: 1.2533 - val_accuracy: 0.4601\n",
      "Epoch 27/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2640 - accuracy: 0.4541 - val_loss: 1.2443 - val_accuracy: 0.4608\n",
      "Epoch 28/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2618 - accuracy: 0.4550 - val_loss: 1.2582 - val_accuracy: 0.4521\n",
      "Epoch 29/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2608 - accuracy: 0.4561 - val_loss: 1.2617 - val_accuracy: 0.4529\n",
      "Epoch 30/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2602 - accuracy: 0.4564 - val_loss: 1.2457 - val_accuracy: 0.4589\n",
      "Epoch 31/50\n",
      "3259/3259 [==============================] - 20s 6ms/step - loss: 1.2613 - accuracy: 0.4552 - val_loss: 1.2524 - val_accuracy: 0.4481\n",
      "Epoch 32/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2598 - accuracy: 0.4563 - val_loss: 1.2668 - val_accuracy: 0.4446\n",
      "Epoch 33/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2593 - accuracy: 0.4554 - val_loss: 1.2735 - val_accuracy: 0.4380\n",
      "Epoch 34/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2604 - accuracy: 0.4541 - val_loss: 1.2503 - val_accuracy: 0.4600\n",
      "Epoch 35/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2598 - accuracy: 0.4533 - val_loss: 1.2480 - val_accuracy: 0.4620\n",
      "Epoch 36/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2618 - accuracy: 0.4526 - val_loss: 1.2694 - val_accuracy: 0.4450\n",
      "Epoch 37/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2610 - accuracy: 0.4547 - val_loss: 1.2506 - val_accuracy: 0.4599\n",
      "Epoch 38/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2604 - accuracy: 0.4533 - val_loss: 1.2464 - val_accuracy: 0.4583\n",
      "Epoch 39/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2605 - accuracy: 0.4540 - val_loss: 1.2641 - val_accuracy: 0.4461\n",
      "Epoch 40/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2594 - accuracy: 0.4548 - val_loss: 1.2554 - val_accuracy: 0.4578\n",
      "Epoch 41/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2590 - accuracy: 0.4550 - val_loss: 1.2598 - val_accuracy: 0.4483\n",
      "Epoch 42/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2593 - accuracy: 0.4536 - val_loss: 1.2493 - val_accuracy: 0.4585\n",
      "Epoch 43/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2596 - accuracy: 0.4555 - val_loss: 1.2424 - val_accuracy: 0.4590\n",
      "Epoch 44/50\n",
      "3259/3259 [==============================] - 20s 6ms/step - loss: 1.2596 - accuracy: 0.4544 - val_loss: 1.2607 - val_accuracy: 0.4595\n",
      "Epoch 45/50\n",
      "3259/3259 [==============================] - 20s 6ms/step - loss: 1.2595 - accuracy: 0.4531 - val_loss: 1.2470 - val_accuracy: 0.4611\n",
      "Epoch 46/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2597 - accuracy: 0.4518 - val_loss: 1.2487 - val_accuracy: 0.4566\n",
      "Epoch 47/50\n",
      "3259/3259 [==============================] - 20s 6ms/step - loss: 1.2596 - accuracy: 0.4548 - val_loss: 1.2465 - val_accuracy: 0.4617\n",
      "Epoch 48/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2612 - accuracy: 0.4533 - val_loss: 1.2583 - val_accuracy: 0.4615\n",
      "Epoch 49/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2599 - accuracy: 0.4542 - val_loss: 1.2453 - val_accuracy: 0.4632\n",
      "Epoch 50/50\n",
      "3259/3259 [==============================] - 20s 6ms/step - loss: 1.2598 - accuracy: 0.4538 - val_loss: 1.2521 - val_accuracy: 0.4542\n",
      "Training for fold 2 ...\n",
      "Epoch 1/50\n",
      "3259/3259 [==============================] - 22s 6ms/step - loss: 1.3764 - accuracy: 0.4160 - val_loss: 1.2820 - val_accuracy: 0.4322\n",
      "Epoch 2/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2887 - accuracy: 0.4359 - val_loss: 1.2680 - val_accuracy: 0.4542\n",
      "Epoch 3/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2841 - accuracy: 0.4426 - val_loss: 1.2691 - val_accuracy: 0.4560\n",
      "Epoch 4/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2818 - accuracy: 0.4400 - val_loss: 1.2796 - val_accuracy: 0.4382\n",
      "Epoch 5/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2791 - accuracy: 0.4436 - val_loss: 1.2674 - val_accuracy: 0.4526\n",
      "Epoch 6/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2781 - accuracy: 0.4454 - val_loss: 1.2640 - val_accuracy: 0.4542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2765 - accuracy: 0.4443 - val_loss: 1.2657 - val_accuracy: 0.4524\n",
      "Epoch 8/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2743 - accuracy: 0.4498 - val_loss: 1.2550 - val_accuracy: 0.4581\n",
      "Epoch 9/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2719 - accuracy: 0.4476 - val_loss: 1.2604 - val_accuracy: 0.4570\n",
      "Epoch 10/50\n",
      "3259/3259 [==============================] - 20s 6ms/step - loss: 1.2721 - accuracy: 0.4486 - val_loss: 1.2510 - val_accuracy: 0.4548\n",
      "Epoch 11/50\n",
      "3259/3259 [==============================] - 25s 8ms/step - loss: 1.2707 - accuracy: 0.4485 - val_loss: 1.2520 - val_accuracy: 0.4605\n",
      "Epoch 12/50\n",
      "3259/3259 [==============================] - 25s 8ms/step - loss: 1.2683 - accuracy: 0.4516 - val_loss: 1.2528 - val_accuracy: 0.4571\n",
      "Epoch 13/50\n",
      "3259/3259 [==============================] - 24s 7ms/step - loss: 1.2673 - accuracy: 0.4509 - val_loss: 1.2485 - val_accuracy: 0.4658\n",
      "Epoch 14/50\n",
      "3259/3259 [==============================] - 29s 9ms/step - loss: 1.2663 - accuracy: 0.4525 - val_loss: 1.2473 - val_accuracy: 0.4643\n",
      "Epoch 15/50\n",
      "3259/3259 [==============================] - 24s 7ms/step - loss: 1.2667 - accuracy: 0.4552 - val_loss: 1.2493 - val_accuracy: 0.4567\n",
      "Epoch 16/50\n",
      "3259/3259 [==============================] - 27s 8ms/step - loss: 1.2647 - accuracy: 0.4518 - val_loss: 1.2501 - val_accuracy: 0.4684\n",
      "Epoch 17/50\n",
      "3259/3259 [==============================] - 29s 9ms/step - loss: 1.2649 - accuracy: 0.4541 - val_loss: 1.2421 - val_accuracy: 0.4672\n",
      "Epoch 18/50\n",
      "3259/3259 [==============================] - 28s 9ms/step - loss: 1.2637 - accuracy: 0.4552 - val_loss: 1.2535 - val_accuracy: 0.4501\n",
      "Epoch 19/50\n",
      "3259/3259 [==============================] - 23s 7ms/step - loss: 1.2643 - accuracy: 0.4527 - val_loss: 1.2521 - val_accuracy: 0.4545\n",
      "Epoch 20/50\n",
      "3259/3259 [==============================] - 25s 8ms/step - loss: 1.2637 - accuracy: 0.4551 - val_loss: 1.2571 - val_accuracy: 0.4491\n",
      "Epoch 21/50\n",
      "3259/3259 [==============================] - 28s 9ms/step - loss: 1.2622 - accuracy: 0.4562 - val_loss: 1.2474 - val_accuracy: 0.4691\n",
      "Epoch 22/50\n",
      "3259/3259 [==============================] - 23s 7ms/step - loss: 1.2646 - accuracy: 0.4505 - val_loss: 1.2506 - val_accuracy: 0.4678\n",
      "Epoch 23/50\n",
      "3259/3259 [==============================] - 24s 7ms/step - loss: 1.2641 - accuracy: 0.4546 - val_loss: 1.2414 - val_accuracy: 0.4678\n",
      "Epoch 24/50\n",
      "3259/3259 [==============================] - 27s 8ms/step - loss: 1.2621 - accuracy: 0.4557 - val_loss: 1.2398 - val_accuracy: 0.4657\n",
      "Epoch 25/50\n",
      "3259/3259 [==============================] - 30s 9ms/step - loss: 1.2625 - accuracy: 0.4559 - val_loss: 1.2552 - val_accuracy: 0.4438\n",
      "Epoch 26/50\n",
      "3259/3259 [==============================] - 30s 9ms/step - loss: 1.2635 - accuracy: 0.4483 - val_loss: 1.2738 - val_accuracy: 0.4371\n",
      "Epoch 27/50\n",
      "3259/3259 [==============================] - 29s 9ms/step - loss: 1.2620 - accuracy: 0.4550 - val_loss: 1.2432 - val_accuracy: 0.4647\n",
      "Epoch 28/50\n",
      "3259/3259 [==============================] - 30s 9ms/step - loss: 1.2602 - accuracy: 0.4535 - val_loss: 1.2383 - val_accuracy: 0.4710\n",
      "Epoch 29/50\n",
      "3259/3259 [==============================] - 28s 9ms/step - loss: 1.2629 - accuracy: 0.4536 - val_loss: 1.2397 - val_accuracy: 0.4653\n",
      "Epoch 30/50\n",
      "3259/3259 [==============================] - 29s 9ms/step - loss: 1.2612 - accuracy: 0.4544 - val_loss: 1.2551 - val_accuracy: 0.4620\n",
      "Epoch 31/50\n",
      "3259/3259 [==============================] - 26s 8ms/step - loss: 1.2617 - accuracy: 0.4555 - val_loss: 1.2491 - val_accuracy: 0.4669\n",
      "Epoch 32/50\n",
      "3259/3259 [==============================] - 26s 8ms/step - loss: 1.2609 - accuracy: 0.4540 - val_loss: 1.2422 - val_accuracy: 0.4668\n",
      "Epoch 33/50\n",
      "3259/3259 [==============================] - 26s 8ms/step - loss: 1.2627 - accuracy: 0.4521 - val_loss: 1.2430 - val_accuracy: 0.4618\n",
      "Epoch 34/50\n",
      "3259/3259 [==============================] - 26s 8ms/step - loss: 1.2616 - accuracy: 0.4563 - val_loss: 1.2439 - val_accuracy: 0.4648\n",
      "Epoch 35/50\n",
      "3259/3259 [==============================] - 25s 8ms/step - loss: 1.2592 - accuracy: 0.4534 - val_loss: 1.2495 - val_accuracy: 0.4580\n",
      "Epoch 36/50\n",
      "3259/3259 [==============================] - 20s 6ms/step - loss: 1.2597 - accuracy: 0.4549 - val_loss: 1.2411 - val_accuracy: 0.4666\n",
      "Epoch 37/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2593 - accuracy: 0.4537 - val_loss: 1.2464 - val_accuracy: 0.4681\n",
      "Epoch 38/50\n",
      "3259/3259 [==============================] - 20s 6ms/step - loss: 1.2600 - accuracy: 0.4556 - val_loss: 1.2562 - val_accuracy: 0.4513\n",
      "Epoch 39/50\n",
      "3259/3259 [==============================] - 20s 6ms/step - loss: 1.2602 - accuracy: 0.4565 - val_loss: 1.2378 - val_accuracy: 0.4727\n",
      "Epoch 40/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2602 - accuracy: 0.4556 - val_loss: 1.2448 - val_accuracy: 0.4566\n",
      "Epoch 41/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2616 - accuracy: 0.4517 - val_loss: 1.2488 - val_accuracy: 0.4572\n",
      "Epoch 42/50\n",
      "3259/3259 [==============================] - 31s 9ms/step - loss: 1.2609 - accuracy: 0.4550 - val_loss: 1.2428 - val_accuracy: 0.4684\n",
      "Epoch 43/50\n",
      "3259/3259 [==============================] - 34s 10ms/step - loss: 1.2604 - accuracy: 0.4536 - val_loss: 1.2505 - val_accuracy: 0.4582\n",
      "Epoch 44/50\n",
      "3259/3259 [==============================] - 34s 10ms/step - loss: 1.2605 - accuracy: 0.4553 - val_loss: 1.2660 - val_accuracy: 0.4364\n",
      "Epoch 45/50\n",
      "3259/3259 [==============================] - 36s 11ms/step - loss: 1.2594 - accuracy: 0.4560 - val_loss: 1.2702 - val_accuracy: 0.4435\n",
      "Epoch 46/50\n",
      "3259/3259 [==============================] - 39s 12ms/step - loss: 1.2593 - accuracy: 0.4544 - val_loss: 1.2415 - val_accuracy: 0.4686\n",
      "Epoch 47/50\n",
      "3259/3259 [==============================] - 33s 10ms/step - loss: 1.2589 - accuracy: 0.4544 - val_loss: 1.2480 - val_accuracy: 0.4567\n",
      "Epoch 48/50\n",
      "3259/3259 [==============================] - 33s 10ms/step - loss: 1.2592 - accuracy: 0.4566 - val_loss: 1.2379 - val_accuracy: 0.4685\n",
      "Epoch 49/50\n",
      "3259/3259 [==============================] - 32s 10ms/step - loss: 1.2598 - accuracy: 0.4551 - val_loss: 1.2689 - val_accuracy: 0.4446\n",
      "Epoch 50/50\n",
      "3259/3259 [==============================] - 36s 11ms/step - loss: 1.2600 - accuracy: 0.4544 - val_loss: 1.2406 - val_accuracy: 0.4657\n",
      "Training for fold 3 ...\n",
      "Epoch 1/50\n",
      "3259/3259 [==============================] - 38s 11ms/step - loss: 1.3829 - accuracy: 0.4194 - val_loss: 1.2891 - val_accuracy: 0.4280\n",
      "Epoch 2/50\n",
      "3259/3259 [==============================] - 34s 10ms/step - loss: 1.2907 - accuracy: 0.4365 - val_loss: 1.2761 - val_accuracy: 0.4427\n",
      "Epoch 3/50\n",
      "3259/3259 [==============================] - 36s 11ms/step - loss: 1.2831 - accuracy: 0.4400 - val_loss: 1.2898 - val_accuracy: 0.4324\n",
      "Epoch 4/50\n",
      "3259/3259 [==============================] - 33s 10ms/step - loss: 1.2788 - accuracy: 0.4414 - val_loss: 1.2697 - val_accuracy: 0.4531\n",
      "Epoch 5/50\n",
      "3259/3259 [==============================] - 34s 11ms/step - loss: 1.2763 - accuracy: 0.4484 - val_loss: 1.2717 - val_accuracy: 0.4550\n",
      "Epoch 6/50\n",
      "3259/3259 [==============================] - 29s 9ms/step - loss: 1.2738 - accuracy: 0.4495 - val_loss: 1.2660 - val_accuracy: 0.4486\n",
      "Epoch 7/50\n",
      "3259/3259 [==============================] - 27s 8ms/step - loss: 1.2728 - accuracy: 0.4506 - val_loss: 1.2634 - val_accuracy: 0.4485\n",
      "Epoch 8/50\n",
      "3259/3259 [==============================] - 28s 9ms/step - loss: 1.2709 - accuracy: 0.4494 - val_loss: 1.2647 - val_accuracy: 0.4457\n",
      "Epoch 9/50\n",
      "3259/3259 [==============================] - 28s 9ms/step - loss: 1.2698 - accuracy: 0.4533 - val_loss: 1.2533 - val_accuracy: 0.4667\n",
      "Epoch 10/50\n",
      "3259/3259 [==============================] - 30s 9ms/step - loss: 1.2691 - accuracy: 0.4552 - val_loss: 1.2845 - val_accuracy: 0.4354\n",
      "Epoch 11/50\n",
      "3259/3259 [==============================] - 20s 6ms/step - loss: 1.2681 - accuracy: 0.4503 - val_loss: 1.2661 - val_accuracy: 0.4550\n",
      "Epoch 12/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2680 - accuracy: 0.4519 - val_loss: 1.2588 - val_accuracy: 0.4542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2672 - accuracy: 0.4521 - val_loss: 1.2512 - val_accuracy: 0.4604\n",
      "Epoch 14/50\n",
      "3259/3259 [==============================] - 18s 6ms/step - loss: 1.2669 - accuracy: 0.4550 - val_loss: 1.2539 - val_accuracy: 0.4572\n",
      "Epoch 15/50\n",
      "3259/3259 [==============================] - 20s 6ms/step - loss: 1.2641 - accuracy: 0.4557 - val_loss: 1.2672 - val_accuracy: 0.4464\n",
      "Epoch 16/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2623 - accuracy: 0.4546 - val_loss: 1.2486 - val_accuracy: 0.4664\n",
      "Epoch 17/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2611 - accuracy: 0.4568 - val_loss: 1.2480 - val_accuracy: 0.4680\n",
      "Epoch 18/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2626 - accuracy: 0.4583 - val_loss: 1.2533 - val_accuracy: 0.4619\n",
      "Epoch 19/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2613 - accuracy: 0.4542 - val_loss: 1.2455 - val_accuracy: 0.4729\n",
      "Epoch 20/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2600 - accuracy: 0.4583 - val_loss: 1.2384 - val_accuracy: 0.4702\n",
      "Epoch 21/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2615 - accuracy: 0.4569 - val_loss: 1.2517 - val_accuracy: 0.4637\n",
      "Epoch 22/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2617 - accuracy: 0.4566 - val_loss: 1.2540 - val_accuracy: 0.4612\n",
      "Epoch 23/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2604 - accuracy: 0.4585 - val_loss: 1.2469 - val_accuracy: 0.4670\n",
      "Epoch 24/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2604 - accuracy: 0.4557 - val_loss: 1.2512 - val_accuracy: 0.4594\n",
      "Epoch 25/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2602 - accuracy: 0.4563 - val_loss: 1.2417 - val_accuracy: 0.4729\n",
      "Epoch 26/50\n",
      "3259/3259 [==============================] - 18s 6ms/step - loss: 1.2597 - accuracy: 0.4577 - val_loss: 1.2432 - val_accuracy: 0.4683\n",
      "Epoch 27/50\n",
      "3259/3259 [==============================] - 18s 6ms/step - loss: 1.2598 - accuracy: 0.4574 - val_loss: 1.2452 - val_accuracy: 0.4684\n",
      "Epoch 28/50\n",
      "3259/3259 [==============================] - 18s 6ms/step - loss: 1.2594 - accuracy: 0.4580 - val_loss: 1.2490 - val_accuracy: 0.4600\n",
      "Epoch 29/50\n",
      "3259/3259 [==============================] - 18s 5ms/step - loss: 1.2591 - accuracy: 0.4579 - val_loss: 1.2517 - val_accuracy: 0.4663\n",
      "Epoch 30/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2568 - accuracy: 0.4576 - val_loss: 1.2411 - val_accuracy: 0.4732\n",
      "Epoch 31/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2568 - accuracy: 0.4602 - val_loss: 1.2469 - val_accuracy: 0.4705\n",
      "Epoch 32/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2589 - accuracy: 0.4561 - val_loss: 1.2395 - val_accuracy: 0.4707\n",
      "Epoch 33/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2581 - accuracy: 0.4601 - val_loss: 1.2519 - val_accuracy: 0.4667\n",
      "Epoch 34/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2570 - accuracy: 0.4604 - val_loss: 1.2409 - val_accuracy: 0.4693\n",
      "Epoch 35/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2572 - accuracy: 0.4550 - val_loss: 1.2386 - val_accuracy: 0.4735\n",
      "Epoch 36/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2556 - accuracy: 0.4583 - val_loss: 1.2466 - val_accuracy: 0.4634\n",
      "Epoch 37/50\n",
      "3259/3259 [==============================] - 18s 5ms/step - loss: 1.2574 - accuracy: 0.4575 - val_loss: 1.2365 - val_accuracy: 0.4766\n",
      "Epoch 38/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2596 - accuracy: 0.4552 - val_loss: 1.2472 - val_accuracy: 0.4729\n",
      "Epoch 39/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2577 - accuracy: 0.4551 - val_loss: 1.2371 - val_accuracy: 0.4782\n",
      "Epoch 40/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2571 - accuracy: 0.4571 - val_loss: 1.2479 - val_accuracy: 0.4635\n",
      "Epoch 41/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2570 - accuracy: 0.4578 - val_loss: 1.2424 - val_accuracy: 0.4707\n",
      "Epoch 42/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2571 - accuracy: 0.4564 - val_loss: 1.2366 - val_accuracy: 0.4734\n",
      "Epoch 43/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2556 - accuracy: 0.4576 - val_loss: 1.2702 - val_accuracy: 0.4545\n",
      "Epoch 44/50\n",
      "3259/3259 [==============================] - 18s 5ms/step - loss: 1.2573 - accuracy: 0.4579 - val_loss: 1.2477 - val_accuracy: 0.4691\n",
      "Epoch 45/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2556 - accuracy: 0.4588 - val_loss: 1.2373 - val_accuracy: 0.4700\n",
      "Epoch 46/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2565 - accuracy: 0.4577 - val_loss: 1.2505 - val_accuracy: 0.4609\n",
      "Epoch 47/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2552 - accuracy: 0.4584 - val_loss: 1.2576 - val_accuracy: 0.4589\n",
      "Epoch 48/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2542 - accuracy: 0.4590 - val_loss: 1.2455 - val_accuracy: 0.4716\n",
      "Epoch 49/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2536 - accuracy: 0.4581 - val_loss: 1.2358 - val_accuracy: 0.4748\n",
      "Epoch 50/50\n",
      "3259/3259 [==============================] - 18s 5ms/step - loss: 1.2538 - accuracy: 0.4588 - val_loss: 1.2462 - val_accuracy: 0.4695\n",
      "Training for fold 4 ...\n",
      "Epoch 1/50\n",
      "3259/3259 [==============================] - 19s 5ms/step - loss: 1.3833 - accuracy: 0.4139 - val_loss: 1.2832 - val_accuracy: 0.4456\n",
      "Epoch 2/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2925 - accuracy: 0.4305 - val_loss: 1.2703 - val_accuracy: 0.4526\n",
      "Epoch 3/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2832 - accuracy: 0.4394 - val_loss: 1.2658 - val_accuracy: 0.4607\n",
      "Epoch 4/50\n",
      "3259/3259 [==============================] - 16s 5ms/step - loss: 1.2760 - accuracy: 0.4487 - val_loss: 1.2564 - val_accuracy: 0.4604\n",
      "Epoch 5/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2719 - accuracy: 0.4505 - val_loss: 1.2535 - val_accuracy: 0.4669\n",
      "Epoch 6/50\n",
      "3259/3259 [==============================] - 16s 5ms/step - loss: 1.2708 - accuracy: 0.4522 - val_loss: 1.2657 - val_accuracy: 0.4605\n",
      "Epoch 7/50\n",
      "3259/3259 [==============================] - 16s 5ms/step - loss: 1.2691 - accuracy: 0.4536 - val_loss: 1.2510 - val_accuracy: 0.4696\n",
      "Epoch 8/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2661 - accuracy: 0.4566 - val_loss: 1.2483 - val_accuracy: 0.4718\n",
      "Epoch 9/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2658 - accuracy: 0.4558 - val_loss: 1.2477 - val_accuracy: 0.4652\n",
      "Epoch 10/50\n",
      "3259/3259 [==============================] - 16s 5ms/step - loss: 1.2617 - accuracy: 0.4590 - val_loss: 1.2518 - val_accuracy: 0.4640\n",
      "Epoch 11/50\n",
      "3259/3259 [==============================] - 16s 5ms/step - loss: 1.2654 - accuracy: 0.4553 - val_loss: 1.2454 - val_accuracy: 0.4670\n",
      "Epoch 12/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2650 - accuracy: 0.4575 - val_loss: 1.2453 - val_accuracy: 0.4720\n",
      "Epoch 13/50\n",
      "3259/3259 [==============================] - 16s 5ms/step - loss: 1.2626 - accuracy: 0.4576 - val_loss: 1.2416 - val_accuracy: 0.4711\n",
      "Epoch 14/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2612 - accuracy: 0.4584 - val_loss: 1.2443 - val_accuracy: 0.4738\n",
      "Epoch 15/50\n",
      "3259/3259 [==============================] - 16s 5ms/step - loss: 1.2622 - accuracy: 0.4560 - val_loss: 1.2537 - val_accuracy: 0.4589\n",
      "Epoch 16/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2624 - accuracy: 0.4591 - val_loss: 1.2387 - val_accuracy: 0.4728\n",
      "Epoch 17/50\n",
      "3259/3259 [==============================] - 16s 5ms/step - loss: 1.2611 - accuracy: 0.4552 - val_loss: 1.2459 - val_accuracy: 0.4680\n",
      "Epoch 18/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2592 - accuracy: 0.4587 - val_loss: 1.2430 - val_accuracy: 0.4684\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3259/3259 [==============================] - 16s 5ms/step - loss: 1.2602 - accuracy: 0.4594 - val_loss: 1.2440 - val_accuracy: 0.4616\n",
      "Epoch 20/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2603 - accuracy: 0.4588 - val_loss: 1.2359 - val_accuracy: 0.4702\n",
      "Epoch 21/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2590 - accuracy: 0.4590 - val_loss: 1.2382 - val_accuracy: 0.4664\n",
      "Epoch 22/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2579 - accuracy: 0.4599 - val_loss: 1.2690 - val_accuracy: 0.4468\n",
      "Epoch 23/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2578 - accuracy: 0.4569 - val_loss: 1.2447 - val_accuracy: 0.4715\n",
      "Epoch 24/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2578 - accuracy: 0.4590 - val_loss: 1.2443 - val_accuracy: 0.4664\n",
      "Epoch 25/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2592 - accuracy: 0.4541 - val_loss: 1.2354 - val_accuracy: 0.4716\n",
      "Epoch 26/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2593 - accuracy: 0.4579 - val_loss: 1.2470 - val_accuracy: 0.4538\n",
      "Epoch 27/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2578 - accuracy: 0.4598 - val_loss: 1.2430 - val_accuracy: 0.4599\n",
      "Epoch 28/50\n",
      "3259/3259 [==============================] - 18s 6ms/step - loss: 1.2573 - accuracy: 0.4593 - val_loss: 1.2474 - val_accuracy: 0.4753\n",
      "Epoch 29/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2558 - accuracy: 0.4598 - val_loss: 1.2402 - val_accuracy: 0.4731\n",
      "Epoch 30/50\n",
      "3259/3259 [==============================] - 19s 6ms/step - loss: 1.2576 - accuracy: 0.4577 - val_loss: 1.2401 - val_accuracy: 0.4722\n",
      "Epoch 31/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2576 - accuracy: 0.4594 - val_loss: 1.2404 - val_accuracy: 0.4701\n",
      "Epoch 32/50\n",
      "3259/3259 [==============================] - 18s 6ms/step - loss: 1.2562 - accuracy: 0.4606 - val_loss: 1.2373 - val_accuracy: 0.4706\n",
      "Epoch 33/50\n",
      "3259/3259 [==============================] - 18s 5ms/step - loss: 1.2572 - accuracy: 0.4594 - val_loss: 1.2362 - val_accuracy: 0.4705\n",
      "Epoch 34/50\n",
      "3259/3259 [==============================] - 17s 5ms/step - loss: 1.2570 - accuracy: 0.4602 - val_loss: 1.2347 - val_accuracy: 0.4744\n",
      "Epoch 35/50\n",
      "3259/3259 [==============================] - 18s 5ms/step - loss: 1.2568 - accuracy: 0.4600 - val_loss: 1.2517 - val_accuracy: 0.4667\n",
      "Epoch 36/50\n",
      "3259/3259 [==============================] - 18s 5ms/step - loss: 1.2546 - accuracy: 0.4621 - val_loss: 1.2384 - val_accuracy: 0.4726\n",
      "Epoch 37/50\n",
      "3259/3259 [==============================] - 18s 5ms/step - loss: 1.2564 - accuracy: 0.4603 - val_loss: 1.2348 - val_accuracy: 0.4713\n",
      "Epoch 38/50\n",
      "3259/3259 [==============================] - 27s 8ms/step - loss: 1.2568 - accuracy: 0.4573 - val_loss: 1.2447 - val_accuracy: 0.4678\n",
      "Epoch 39/50\n",
      "3259/3259 [==============================] - 35s 11ms/step - loss: 1.2535 - accuracy: 0.4605 - val_loss: 1.2415 - val_accuracy: 0.4718\n",
      "Epoch 40/50\n",
      "3259/3259 [==============================] - 31s 9ms/step - loss: 1.2565 - accuracy: 0.4617 - val_loss: 1.2339 - val_accuracy: 0.4753\n",
      "Epoch 41/50\n",
      "3259/3259 [==============================] - 35s 11ms/step - loss: 1.2570 - accuracy: 0.4590 - val_loss: 1.2693 - val_accuracy: 0.4419\n",
      "Epoch 42/50\n",
      "3259/3259 [==============================] - 35s 11ms/step - loss: 1.2566 - accuracy: 0.4594 - val_loss: 1.2458 - val_accuracy: 0.4683\n",
      "Epoch 43/50\n",
      "3259/3259 [==============================] - 32s 10ms/step - loss: 1.2562 - accuracy: 0.4588 - val_loss: 1.2321 - val_accuracy: 0.4721\n",
      "Epoch 44/50\n",
      "3259/3259 [==============================] - 34s 10ms/step - loss: 1.2563 - accuracy: 0.4580 - val_loss: 1.2307 - val_accuracy: 0.4715\n",
      "Epoch 45/50\n",
      "3259/3259 [==============================] - 35s 11ms/step - loss: 1.2542 - accuracy: 0.4621 - val_loss: 1.2476 - val_accuracy: 0.4593\n",
      "Epoch 46/50\n",
      "3259/3259 [==============================] - 37s 11ms/step - loss: 1.2545 - accuracy: 0.4618 - val_loss: 1.2311 - val_accuracy: 0.4785\n",
      "Epoch 47/50\n",
      "3259/3259 [==============================] - 33s 10ms/step - loss: 1.2545 - accuracy: 0.4598 - val_loss: 1.2393 - val_accuracy: 0.4718\n",
      "Epoch 48/50\n",
      "3259/3259 [==============================] - 37s 11ms/step - loss: 1.2566 - accuracy: 0.4586 - val_loss: 1.2396 - val_accuracy: 0.4705\n",
      "Epoch 49/50\n",
      "3259/3259 [==============================] - 39s 12ms/step - loss: 1.2552 - accuracy: 0.4605 - val_loss: 1.2357 - val_accuracy: 0.4706\n",
      "Epoch 50/50\n",
      "3259/3259 [==============================] - 37s 11ms/step - loss: 1.2550 - accuracy: 0.4620 - val_loss: 1.2488 - val_accuracy: 0.4569\n",
      "Training for fold 5 ...\n",
      "Epoch 1/50\n",
      "3259/3259 [==============================] - 37s 11ms/step - loss: 1.3776 - accuracy: 0.4165 - val_loss: 1.2924 - val_accuracy: 0.4306\n",
      "Epoch 2/50\n",
      "3259/3259 [==============================] - 36s 11ms/step - loss: 1.2921 - accuracy: 0.4280 - val_loss: 1.2903 - val_accuracy: 0.4384\n",
      "Epoch 3/50\n",
      "3259/3259 [==============================] - 33s 10ms/step - loss: 1.2849 - accuracy: 0.4351 - val_loss: 1.2768 - val_accuracy: 0.4479\n",
      "Epoch 4/50\n",
      "3259/3259 [==============================] - 34s 11ms/step - loss: 1.2814 - accuracy: 0.4394 - val_loss: 1.2757 - val_accuracy: 0.4491\n",
      "Epoch 5/50\n",
      "3259/3259 [==============================] - 32s 10ms/step - loss: 1.2782 - accuracy: 0.4383 - val_loss: 1.2698 - val_accuracy: 0.4494\n",
      "Epoch 6/50\n",
      "3259/3259 [==============================] - 38s 12ms/step - loss: 1.2785 - accuracy: 0.4388 - val_loss: 1.2674 - val_accuracy: 0.4513\n",
      "Epoch 7/50\n",
      "3259/3259 [==============================] - 37s 11ms/step - loss: 1.2748 - accuracy: 0.4432 - val_loss: 1.2703 - val_accuracy: 0.4544\n",
      "Epoch 8/50\n",
      "3259/3259 [==============================] - 36s 11ms/step - loss: 1.2751 - accuracy: 0.4426 - val_loss: 1.2706 - val_accuracy: 0.4463\n",
      "Epoch 9/50\n",
      "3259/3259 [==============================] - 37s 11ms/step - loss: 1.2723 - accuracy: 0.4440 - val_loss: 1.2643 - val_accuracy: 0.4554\n",
      "Epoch 10/50\n",
      "3259/3259 [==============================] - 32s 10ms/step - loss: 1.2708 - accuracy: 0.4475 - val_loss: 1.2806 - val_accuracy: 0.4462\n",
      "Epoch 11/50\n",
      "3259/3259 [==============================] - 35s 11ms/step - loss: 1.2711 - accuracy: 0.4453 - val_loss: 1.2895 - val_accuracy: 0.4364\n",
      "Epoch 12/50\n",
      "3259/3259 [==============================] - 36s 11ms/step - loss: 1.2700 - accuracy: 0.4436 - val_loss: 1.2609 - val_accuracy: 0.4556\n",
      "Epoch 13/50\n",
      "3259/3259 [==============================] - 36s 11ms/step - loss: 1.2682 - accuracy: 0.4457 - val_loss: 1.2616 - val_accuracy: 0.4578\n",
      "Epoch 14/50\n",
      "3259/3259 [==============================] - 36s 11ms/step - loss: 1.2672 - accuracy: 0.4503 - val_loss: 1.3021 - val_accuracy: 0.4291\n",
      "Epoch 15/50\n",
      "3259/3259 [==============================] - 31s 9ms/step - loss: 1.2661 - accuracy: 0.4502 - val_loss: 1.2574 - val_accuracy: 0.4559\n",
      "Epoch 16/50\n",
      "3259/3259 [==============================] - 28s 9ms/step - loss: 1.2649 - accuracy: 0.4497 - val_loss: 1.2618 - val_accuracy: 0.4538\n",
      "Epoch 17/50\n",
      "3259/3259 [==============================] - 26s 8ms/step - loss: 1.2643 - accuracy: 0.4533 - val_loss: 1.2698 - val_accuracy: 0.4430\n",
      "Epoch 18/50\n",
      "3259/3259 [==============================] - 28s 8ms/step - loss: 1.2655 - accuracy: 0.4505 - val_loss: 1.2607 - val_accuracy: 0.4553\n",
      "Epoch 19/50\n",
      "3259/3259 [==============================] - 30s 9ms/step - loss: 1.2629 - accuracy: 0.4534 - val_loss: 1.2543 - val_accuracy: 0.4580\n",
      "Epoch 20/50\n",
      "3259/3259 [==============================] - 33s 10ms/step - loss: 1.2629 - accuracy: 0.4519 - val_loss: 1.2496 - val_accuracy: 0.4630\n",
      "Epoch 21/50\n",
      "3259/3259 [==============================] - 31s 10ms/step - loss: 1.2618 - accuracy: 0.4561 - val_loss: 1.2578 - val_accuracy: 0.4567\n",
      "Epoch 22/50\n",
      "3259/3259 [==============================] - 32s 10ms/step - loss: 1.2620 - accuracy: 0.4552 - val_loss: 1.2497 - val_accuracy: 0.4614\n",
      "Epoch 23/50\n",
      "3259/3259 [==============================] - 32s 10ms/step - loss: 1.2633 - accuracy: 0.4530 - val_loss: 1.2581 - val_accuracy: 0.4577\n",
      "Epoch 24/50\n",
      "3259/3259 [==============================] - 31s 9ms/step - loss: 1.2618 - accuracy: 0.4528 - val_loss: 1.2511 - val_accuracy: 0.4613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50\n",
      "3259/3259 [==============================] - 32s 10ms/step - loss: 1.2618 - accuracy: 0.4531 - val_loss: 1.2521 - val_accuracy: 0.4673\n",
      "Epoch 26/50\n",
      "3259/3259 [==============================] - 29s 9ms/step - loss: 1.2591 - accuracy: 0.4533 - val_loss: 1.2559 - val_accuracy: 0.4588\n",
      "Epoch 27/50\n",
      "3259/3259 [==============================] - 29s 9ms/step - loss: 1.2606 - accuracy: 0.4556 - val_loss: 1.2560 - val_accuracy: 0.4569\n",
      "Epoch 28/50\n",
      "3259/3259 [==============================] - 29s 9ms/step - loss: 1.2597 - accuracy: 0.4543 - val_loss: 1.2460 - val_accuracy: 0.4691\n",
      "Epoch 29/50\n",
      "3259/3259 [==============================] - 36s 11ms/step - loss: 1.2602 - accuracy: 0.4551 - val_loss: 1.2654 - val_accuracy: 0.4534\n",
      "Epoch 30/50\n",
      "3259/3259 [==============================] - 34s 11ms/step - loss: 1.2600 - accuracy: 0.4575 - val_loss: 1.2551 - val_accuracy: 0.4635\n",
      "Epoch 31/50\n",
      "3259/3259 [==============================] - 35s 11ms/step - loss: 1.2586 - accuracy: 0.4561 - val_loss: 1.2526 - val_accuracy: 0.4646\n",
      "Epoch 32/50\n",
      "3259/3259 [==============================] - 36s 11ms/step - loss: 1.2595 - accuracy: 0.4538 - val_loss: 1.2460 - val_accuracy: 0.4683\n",
      "Epoch 33/50\n",
      "3259/3259 [==============================] - 30s 9ms/step - loss: 1.2597 - accuracy: 0.4547 - val_loss: 1.2477 - val_accuracy: 0.4613\n",
      "Epoch 34/50\n",
      "3259/3259 [==============================] - 32s 10ms/step - loss: 1.2586 - accuracy: 0.4567 - val_loss: 1.2489 - val_accuracy: 0.4620\n",
      "Epoch 35/50\n",
      "3259/3259 [==============================] - 30s 9ms/step - loss: 1.2569 - accuracy: 0.4582 - val_loss: 1.2773 - val_accuracy: 0.4470\n",
      "Epoch 36/50\n",
      "3259/3259 [==============================] - 30s 9ms/step - loss: 1.2553 - accuracy: 0.4600 - val_loss: 1.2470 - val_accuracy: 0.4680\n",
      "Epoch 37/50\n",
      "3259/3259 [==============================] - 33s 10ms/step - loss: 1.2578 - accuracy: 0.4544 - val_loss: 1.2484 - val_accuracy: 0.4616\n",
      "Epoch 38/50\n",
      "3259/3259 [==============================] - 28s 9ms/step - loss: 1.2572 - accuracy: 0.4544 - val_loss: 1.2457 - val_accuracy: 0.4623\n",
      "Epoch 39/50\n",
      "3259/3259 [==============================] - 34s 11ms/step - loss: 1.2558 - accuracy: 0.4573 - val_loss: 1.2688 - val_accuracy: 0.4467\n",
      "Epoch 40/50\n",
      "3259/3259 [==============================] - 33s 10ms/step - loss: 1.2578 - accuracy: 0.4566 - val_loss: 1.2511 - val_accuracy: 0.4592\n",
      "Epoch 41/50\n",
      "3259/3259 [==============================] - 34s 10ms/step - loss: 1.2565 - accuracy: 0.4570 - val_loss: 1.2463 - val_accuracy: 0.4672\n",
      "Epoch 42/50\n",
      "3259/3259 [==============================] - 37s 11ms/step - loss: 1.2562 - accuracy: 0.4589 - val_loss: 1.2437 - val_accuracy: 0.4677\n",
      "Epoch 43/50\n",
      "3259/3259 [==============================] - 38s 12ms/step - loss: 1.2570 - accuracy: 0.4582 - val_loss: 1.2453 - val_accuracy: 0.4646\n",
      "Epoch 44/50\n",
      "3259/3259 [==============================] - 35s 11ms/step - loss: 1.2557 - accuracy: 0.4570 - val_loss: 1.2549 - val_accuracy: 0.4604\n",
      "Epoch 45/50\n",
      "3259/3259 [==============================] - 37s 11ms/step - loss: 1.2550 - accuracy: 0.4599 - val_loss: 1.2490 - val_accuracy: 0.4652\n",
      "Epoch 46/50\n",
      "3259/3259 [==============================] - 36s 11ms/step - loss: 1.2543 - accuracy: 0.4598 - val_loss: 1.2408 - val_accuracy: 0.4659\n",
      "Epoch 47/50\n",
      "3259/3259 [==============================] - 33s 10ms/step - loss: 1.2550 - accuracy: 0.4583 - val_loss: 1.2481 - val_accuracy: 0.4600\n",
      "Epoch 48/50\n",
      "3259/3259 [==============================] - 36s 11ms/step - loss: 1.2558 - accuracy: 0.4621 - val_loss: 1.2528 - val_accuracy: 0.4600\n",
      "Epoch 49/50\n",
      "3259/3259 [==============================] - 29s 9ms/step - loss: 1.2560 - accuracy: 0.4584 - val_loss: 1.2494 - val_accuracy: 0.4571\n",
      "Epoch 50/50\n",
      "3259/3259 [==============================] - 30s 9ms/step - loss: 1.2537 - accuracy: 0.4581 - val_loss: 1.2596 - val_accuracy: 0.4506\n",
      "Fold 1 - Loss: 1.252086877822876 - Accuracy: 0.4542219042778015\n",
      "Fold 2 - Loss: 1.240600347518921 - Accuracy: 0.4656929075717926\n",
      "Fold 3 - Loss: 1.2462396621704102 - Accuracy: 0.4694979786872864\n",
      "Fold 4 - Loss: 1.2488371133804321 - Accuracy: 0.45685529708862305\n",
      "Fold 5 - Loss: 1.259586215019226 - Accuracy: 0.45059531927108765\n",
      "Average scores for all folds - Loss: 1.249470043182373 - Accuracy: 0.45937268137931825\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0],119,1)\n",
    "X_test = X_test.reshape(X_test.shape[0],119,1)\n",
    "\n",
    "y_train = to_categorical(y_train, 4)\n",
    "y_test = to_categorical(y_test, 4)\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "fold_no = 1\n",
    "models = []\n",
    "scores = []\n",
    "\n",
    "for train, test in kfold.split(X_train, y_train):\n",
    "    # 创建模型\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu',\n",
    "                     input_shape=(X_train.shape[1], 1),\n",
    "                     kernel_regularizer=l2(0.01))) # 添加L2正则化\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=32, kernel_size=3, activation='relu',\n",
    "                     kernel_regularizer=l2(0.01))) # 添加L2正则化\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu', kernel_regularizer=l2(0.01))) # 添加L2正则化\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation='relu', kernel_regularizer=l2(0.01))) # 添加L2正则化\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "    # 编译模型\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=2)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    # 训练模型\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    history = model.fit(X_train[train], y_train[train],\n",
    "                        epochs=50,\n",
    "                        verbose=1,\n",
    "                        batch_size=10,\n",
    "                        callbacks=[early_stopping],\n",
    "                        validation_data=(X_train[test], y_train[test]))\n",
    "\n",
    "    # 评估模型\n",
    "    models.append(model)\n",
    "    scores.append(model.evaluate(X_train[test], y_train[test], verbose=0))\n",
    "    fold_no += 1\n",
    "\n",
    "# 打印每个折叠的准确率以及平均准确率\n",
    "for i in range(len(scores)):\n",
    "    print(f'Fold {i+1} - Loss: {scores[i][0]} - Accuracy: {scores[i][1]}')\n",
    "print(f'Average scores for all folds - Loss: {np.mean([s[0] for s in scores])} - Accuracy: {np.mean([s[1] for s in scores])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319/319 [==============================] - 2s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "best_fold = np.argmax([score[1] for score in scores])\n",
    "best_model = models[best_fold]\n",
    "y_pred = best_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果y_test是one-hot编码的，将其转换为整数标签\n",
    "if len(y_test.shape) == 2 and y_test.shape[1] > 1:\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "# 如果y_pred是概率，取概率最大的索引作为预测类别\n",
    "if len(y_pred.shape) == 2 and y_pred.shape[1] > 1:\n",
    "    y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.56      0.57      3400\n",
      "           1       0.00      0.00      0.00      2028\n",
      "           2       0.40      0.66      0.50      3162\n",
      "           3       0.45      0.47      0.46      1594\n",
      "\n",
      "    accuracy                           0.47     10184\n",
      "   macro avg       0.36      0.42      0.38     10184\n",
      "weighted avg       0.39      0.47      0.42     10184\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
