{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.optimizers import adam_v2\n",
    "import keras_metrics\n",
    "from keras import metrics\n",
    "from sklearn.datasets import make_classification\n",
    "import keras\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train_preprocessed-nonPCA.csv',index_col=[0])\n",
    "df_test = pd.read_csv('test_preprocessed-nonPCA.csv',index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40736, 118)\n",
      "(40736,)\n",
      "(10184, 118)\n",
      "(10184,)\n"
     ]
    }
   ],
   "source": [
    "X_train=df_train.iloc[:,:-1]\n",
    "y_train=df_train.iloc[:,-1]\n",
    "X_test=df_test.iloc[:,:-1]\n",
    "y_test=df_test.iloc[:,-1]\n",
    "\n",
    "# print the shape of the split dataset\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for N=20:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.67      0.58      3400\n",
      "           1       0.17      0.00      0.00      2028\n",
      "           2       0.41      0.62      0.50      3162\n",
      "           3       0.50      0.28      0.36      1594\n",
      "\n",
      "    accuracy                           0.46     10184\n",
      "   macro avg       0.40      0.39      0.36     10184\n",
      "weighted avg       0.41      0.46      0.40     10184\n",
      "\n",
      "Multi-class AUROC (One-vs-Rest) for N=20: 0.6844397832180069\n",
      "Classification report for N=50:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.68      0.59      3400\n",
      "           1       0.38      0.00      0.01      2028\n",
      "           2       0.42      0.63      0.50      3162\n",
      "           3       0.54      0.31      0.39      1594\n",
      "\n",
      "    accuracy                           0.47     10184\n",
      "   macro avg       0.46      0.41      0.37     10184\n",
      "weighted avg       0.46      0.47      0.41     10184\n",
      "\n",
      "Multi-class AUROC (One-vs-Rest) for N=50: 0.6965047926648125\n",
      "Classification report for N=80:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.69      0.59      3400\n",
      "           1       0.32      0.01      0.02      2028\n",
      "           2       0.42      0.63      0.50      3162\n",
      "           3       0.55      0.32      0.40      1594\n",
      "\n",
      "    accuracy                           0.48     10184\n",
      "   macro avg       0.45      0.41      0.38     10184\n",
      "weighted avg       0.45      0.48      0.42     10184\n",
      "\n",
      "Multi-class AUROC (One-vs-Rest) for N=80: 0.702537633613157\n",
      "Classification report for N=100:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.69      0.60      3400\n",
      "           1       0.32      0.01      0.02      2028\n",
      "           2       0.42      0.63      0.51      3162\n",
      "           3       0.55      0.32      0.41      1594\n",
      "\n",
      "    accuracy                           0.48     10184\n",
      "   macro avg       0.46      0.41      0.38     10184\n",
      "weighted avg       0.46      0.48      0.42     10184\n",
      "\n",
      "Multi-class AUROC (One-vs-Rest) for N=100: 0.7038332314824078\n",
      "Classification report for N=118:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.69      0.60      3400\n",
      "           1       0.32      0.01      0.02      2028\n",
      "           2       0.42      0.63      0.51      3162\n",
      "           3       0.55      0.32      0.41      1594\n",
      "\n",
      "    accuracy                           0.48     10184\n",
      "   macro avg       0.46      0.41      0.38     10184\n",
      "weighted avg       0.46      0.48      0.42     10184\n",
      "\n",
      "Multi-class AUROC (One-vs-Rest) for N=118: 0.7036571135267801\n",
      "Best AUROC: 0.7038332314824078 with N=100\n"
     ]
    }
   ],
   "source": [
    "# 定义N值列表\n",
    "N_values = [20, 50, 80, 100, 118]\n",
    "\n",
    "# 初始化记录最佳AUROC和最佳N值的变量\n",
    "best_auroc = 0\n",
    "best_N = 0\n",
    "\n",
    "# 遍历N值\n",
    "for N in N_values:\n",
    "    # 计算相关性并选择前N个特征\n",
    "    correlation_matrix = df_train.corr()\n",
    "    abs_target_correlation = correlation_matrix['aki'].abs()\n",
    "    top_features = abs_target_correlation.drop('aki', axis=0).nlargest(N).index.tolist()\n",
    "    top_features_indices = [X_train.columns.get_loc(col) for col in top_features]\n",
    "\n",
    "\n",
    "    # 根据选定的特征更新训练和测试集\n",
    "    X_train_selected = X_train.iloc[:, top_features_indices]\n",
    "    X_test_selected = X_test.iloc[:, top_features_indices]\n",
    "\n",
    "    # 训练逻辑回归模型\n",
    "    model = LogisticRegression(max_iter=1000)  # 增加迭代次数以确保收敛\n",
    "    model.fit(X_train_selected, y_train)\n",
    "\n",
    "    # 进行预测\n",
    "    y_pred = model.predict(X_test_selected)\n",
    "\n",
    "    # 计算并打印分类报告\n",
    "    print(f\"Classification report for N={N}:\\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "    # 计算AUROC\n",
    "    y_pred_proba = model.predict_proba(X_test_selected)\n",
    "    auroc = roc_auc_score(y_test, y_pred_proba, multi_class=\"ovr\", average=\"macro\")\n",
    "    print(f\"Multi-class AUROC (One-vs-Rest) for N={N}: {auroc}\")\n",
    "\n",
    "    # 更新最佳AUROC和N值\n",
    "    if auroc > best_auroc:\n",
    "        best_auroc = auroc\n",
    "        best_N = N\n",
    "\n",
    "# 打印最佳AUROC和对应的N值\n",
    "print(f\"Best AUROC: {best_auroc} with N={best_N}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
